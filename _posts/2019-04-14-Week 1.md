---
layout: post
title: Week 1
---

For our first benchmark, we wanted to design a base for Nibl and get started on voice recognition.

Our base design contains an area for the BeagleBone Blue, a breadboard, the servo for spinning the entire base, and the servo that changes the launch angle.

![cad base 1]({{ site.baseurl }}/images/baseday1.png "cadbase1")
![cad base 2]({{ site.baseurl }}/images/base2day1.png "cadbase2")

We got that printed the next morning, and fired up the servos! We had to file the breadboard and dremel the print to get it to fit, and we miiight have forgotten a place to put the battery. But we're spinning and feeling good.

![gif of Nible spinning](https://giphy.com/gifs/4NnXKputOP86lcUnES)

As for voice recognition, we decided to prototype what we'll finally implement on the MCU in Python on a laptop. Now, we probably don't want to do the voice recognition the ESE 224 way. That is:
+ Take an FFT of an input signal
+ Dot it with a whole lot of labeled sample FFTs
+ Find the highest dot product, and assign the input signal that label.
The weaknesses of this method are:
+ Very specific to one voice
+ Requires a huge amount of data and comparing
+ Not good at identifying a signal that's just noise.


